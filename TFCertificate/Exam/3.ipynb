{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4820878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 20:35:02.421156: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/home/irfanrah/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-02-26 20:35:02.421177: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 206 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 20:35:50.575425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 20:35:50.575748: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/home/irfanrah/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-02-26 20:35:50.575802: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/home/irfanrah/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-02-26 20:35:50.575852: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/home/irfanrah/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-02-26 20:35:50.577095: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/home/irfanrah/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-02-26 20:35:50.577147: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/home/irfanrah/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-02-26 20:35:50.577196: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/home/irfanrah/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-02-26 20:35:50.577204: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-02-26 20:35:50.577403: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/tmp/ipykernel_21245/3830677376.py:93: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 20:35:51.507791: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 737280000 exceeds 10% of free system memory.\n",
      "2022-02-26 20:35:51.637694: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 737280000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/7 [===>..........................] - ETA: 27s - loss: 0.8193 - acc: 0.5312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 20:35:55.636672: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 737280000 exceeds 10% of free system memory.\n",
      "2022-02-26 20:35:55.741354: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 737280000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2/7 [=======>......................] - ETA: 20s - loss: 1.9367 - acc: 0.5469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 20:35:59.750282: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 737280000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 34s 5s/step - loss: 1.3843 - acc: 0.6359 - val_loss: 0.1148 - val_acc: 0.9600\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 37s 6s/step - loss: 0.2529 - acc: 0.8835 - val_loss: 0.0937 - val_acc: 0.9600\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 37s 5s/step - loss: 0.0228 - acc: 0.9903 - val_loss: 0.0208 - val_acc: 0.9800\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 37s 5s/step - loss: 0.0467 - acc: 0.9806 - val_loss: 0.0141 - val_acc: 0.9800\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 37s 5s/step - loss: 0.0084 - acc: 0.9951 - val_loss: 2.7848e-04 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 37s 5s/step - loss: 2.0865e-05 - acc: 1.0000 - val_loss: 1.0916e-04 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 37s 5s/step - loss: 3.2839e-06 - acc: 1.0000 - val_loss: 2.0243e-04 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 37s 5s/step - loss: 3.4692e-06 - acc: 1.0000 - val_loss: 3.0093e-04 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 35s 5s/step - loss: 4.0264e-06 - acc: 1.0000 - val_loss: 3.7002e-04 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 37s 6s/step - loss: 4.4072e-06 - acc: 1.0000 - val_loss: 4.1052e-04 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
    "# Please note that the weight of the grade for the question is relative\n",
    "# to its difficulty. So your Category 1 question will score significantly\n",
    "# less than your Category 5 question.\n",
    "#\n",
    "# Don't use lambda layers in your model.\n",
    "# You do not need them to solve the question.\n",
    "# Lambda layers are not supported by the grading infrastructure.\n",
    "#\n",
    "# You must use the Submit and Test button to submit your model\n",
    "# at least once in this category before you finally submit your exam,\n",
    "# otherwise you will score zero for this category.\n",
    "# ======================================================================\n",
    "#\n",
    "# Computer vision with CNNs\n",
    "#\n",
    "# Create and train a classifier for horses or humans using the provided data.\n",
    "# Make sure your final layer is a 1 neuron, activated by sigmoid as shown.\n",
    "#\n",
    "# The test will use images that are 300x300 with 3 bytes color depth so be sure to\n",
    "# design your neural network accordingly\n",
    "\n",
    "import tensorflow as tf\n",
    "import urllib\n",
    "import zipfile\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg19 import VGG19,preprocess_input\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "\n",
    "\n",
    "def solution_model():\n",
    "    _TRAIN_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\n",
    "    _TEST_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\n",
    "    urllib.request.urlretrieve(_TRAIN_URL, 'horse-or-human.zip')\n",
    "    local_zip = 'horse-or-human.zip'\n",
    "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "    zip_ref.extractall('tmp/horse-or-human/')\n",
    "    zip_ref.close()\n",
    "    urllib.request.urlretrieve(_TEST_URL, 'testdata.zip')\n",
    "    local_zip = 'testdata.zip'\n",
    "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "    zip_ref.extractall('tmp/testdata/')\n",
    "    zip_ref.close()\n",
    "    \n",
    "    FILE_TRAIN_DIR = 'tmp/testdata/'\n",
    "\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale = 1/255.0 ,validation_split=0.2) \n",
    "        #Your code here. Should at least have a rescale. Other parameters can help with overfitting.)\n",
    "\n",
    "    #validation_datagen = ImageDataGenerator(rescale = 1/255.0)\n",
    "        #Your Code here)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(FILE_TRAIN_DIR, \n",
    "                                                        batch_size = 32, \n",
    "                                                        class_mode = 'categorical' , \n",
    "                                                        target_size = (300,300),\n",
    "                                                        subset='training')\n",
    "        #Your Code Here)\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_directory(FILE_TRAIN_DIR,\n",
    "        target_size=(300, 300),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "        #Your Code Here)\n",
    "        \n",
    "    vgg = VGG19( include_top = False,\n",
    "            input_shape = (300,300,3),\n",
    "            weights = 'imagenet')\n",
    "    \n",
    "    for layer in vgg.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    x = Flatten()(vgg.output)\n",
    "    prediction = Dense( 2 , activation = 'softmax' )(x)\n",
    "    model = Model( inputs = vgg.input , outputs = prediction )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=['acc'])\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        validation_data=validation_generator)\n",
    "    return model\n",
    "\n",
    "    # NOTE: If training is taking a very long time, you should consider setting the batch size\n",
    "    # appropriately on the generator, and the steps per epoch in the model.fit() function.\n",
    "\n",
    "# Note that you'll need to save your model as a .h5 like this.\n",
    "# When you press the Submit and Test button, your saved .h5 model will\n",
    "# be sent to the testing infrastructure for scoring\n",
    "# and the score will be returned to you.\n",
    "if __name__ == '__main__':\n",
    "    model = solution_model()\n",
    "    model.save(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ccfc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import urllib\n",
    "import zipfile\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "_TRAIN_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\n",
    "_TEST_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\n",
    "urllib.request.urlretrieve(_TRAIN_URL, 'horse-or-human.zip')\n",
    "local_zip = 'horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('tmp/horse-or-human/')\n",
    "zip_ref.close()\n",
    "urllib.request.urlretrieve(_TEST_URL, 'testdata.zip')\n",
    "local_zip = 'testdata.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('tmp/testdata/')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c89c8501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horses\thumans\r\n"
     ]
    }
   ],
   "source": [
    "!ls tmp/testdata/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c6daa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse1-000.png\thorse2-183.png\thorse3-397.png\thorse4-503.png\thorse5-360.png\r\n",
      "horse1-105.png\thorse2-201.png\thorse3-416.png\thorse4-530.png\thorse5-400.png\r\n",
      "horse1-122.png\thorse2-218.png\thorse3-440.png\thorse4-541.png\thorse5-402.png\r\n",
      "horse1-127.png\thorse2-224.png\thorse3-469.png\thorse4-548.png\thorse5-405.png\r\n",
      "horse1-170.png\thorse2-254.png\thorse3-484.png\thorse4-556.png\thorse5-458.png\r\n",
      "horse1-204.png\thorse2-269.png\thorse3-498.png\thorse4-588.png\thorse5-478.png\r\n",
      "horse1-224.png\thorse2-294.png\thorse3-521.png\thorse4-599.png\thorse5-488.png\r\n",
      "horse1-241.png\thorse2-314.png\thorse3-541.png\thorse5-002.png\thorse5-504.png\r\n",
      "horse1-264.png\thorse2-368.png\thorse3-584.png\thorse5-018.png\thorse5-514.png\r\n",
      "horse1-276.png\thorse2-383.png\thorse4-000.png\thorse5-032.png\thorse5-519.png\r\n",
      "horse1-298.png\thorse2-412.png\thorse4-014.png\thorse5-060.png\thorse5-550.png\r\n",
      "horse1-335.png\thorse2-441.png\thorse4-043.png\thorse5-065.png\thorse5-565.png\r\n",
      "horse1-384.png\thorse2-544.png\thorse4-072.png\thorse5-076.png\thorse5-589.png\r\n",
      "horse1-411.png\thorse2-582.png\thorse4-102.png\thorse5-083.png\thorse6-004.png\r\n",
      "horse1-436.png\thorse2-596.png\thorse4-159.png\thorse5-100.png\thorse6-064.png\r\n",
      "horse1-455.png\thorse3-011.png\thorse4-188.png\thorse5-103.png\thorse6-089.png\r\n",
      "horse1-484.png\thorse3-026.png\thorse4-202.png\thorse5-123.png\thorse6-153.png\r\n",
      "horse1-510.png\thorse3-055.png\thorse4-232.png\thorse5-164.png\thorse6-161.png\r\n",
      "horse1-539.png\thorse3-070.png\thorse4-302.png\thorse5-181.png\thorse6-198.png\r\n",
      "horse1-554.png\thorse3-099.png\thorse4-345.png\thorse5-192.png\thorse6-218.png\r\n",
      "horse1-568.png\thorse3-141.png\thorse4-389.png\thorse5-203.png\thorse6-275.png\r\n",
      "horse2-011.png\thorse3-171.png\thorse4-403.png\thorse5-235.png\thorse6-345.png\r\n",
      "horse2-040.png\thorse3-198.png\thorse4-439.png\thorse5-259.png\thorse6-403.png\r\n",
      "horse2-069.png\thorse3-217.png\thorse4-468.png\thorse5-275.png\thorse6-544.png\r\n",
      "horse2-112.png\thorse3-255.png\thorse4-495.png\thorse5-303.png\r\n",
      "horse2-136.png\thorse3-326.png\thorse4-501.png\thorse5-342.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls tmp/testdata/horses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b23f3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
