{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c318b2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 17:01:22.859189: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/home/irfanrah/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-02-26 17:01:22.859210: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n",
      "11501568/11490434 [==============================] - 3s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 17:01:27.811486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 17:01:27.811827: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/home/irfanrah/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-02-26 17:01:27.811898: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/home/irfanrah/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-02-26 17:01:27.811955: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/home/irfanrah/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-02-26 17:01:28.127612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/home/irfanrah/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-02-26 17:01:28.127746: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/home/irfanrah/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-02-26 17:01:28.127858: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/home/irfanrah/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-02-26 17:01:28.127874: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-02-26 17:01:28.128273: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/irfanrah/tf2certify/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2756 - acc: 0.9143 - val_loss: 0.0559 - val_acc: 0.9824\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1077 - acc: 0.9671 - val_loss: 0.0400 - val_acc: 0.9863\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0856 - acc: 0.9746 - val_loss: 0.0366 - val_acc: 0.9884\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0731 - acc: 0.9770 - val_loss: 0.0312 - val_acc: 0.9903\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0646 - acc: 0.9797 - val_loss: 0.0295 - val_acc: 0.9903\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0610 - acc: 0.9815 - val_loss: 0.0268 - val_acc: 0.9911\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0573 - acc: 0.9821 - val_loss: 0.0248 - val_acc: 0.9916\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0522 - acc: 0.9834 - val_loss: 0.0246 - val_acc: 0.9922\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0506 - acc: 0.9840 - val_loss: 0.0217 - val_acc: 0.9920\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0474 - acc: 0.9853 - val_loss: 0.0273 - val_acc: 0.9914\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
    "# Please note that the weight of the grade for the question is relative\n",
    "# to its difficulty. So your Category 1 question will score significantly\n",
    "# less than your Category 5 question.\n",
    "#\n",
    "# Don't use lambda layers in your model.\n",
    "# You do not need them to solve the question.\n",
    "# Lambda layers are not supported by the grading infrastructure.\n",
    "#\n",
    "# You must use the Submit and Test button to submit your model\n",
    "# at least once in this category before you finally submit your exam,\n",
    "# otherwise you will score zero for this category.\n",
    "# ======================================================================\n",
    "#\n",
    "# Basic Datasets Question\n",
    "#\n",
    "# Create and train a classifier for the MNIST dataset.\n",
    "# Note that the test will expect it to classify 10 classes and that the \n",
    "# input shape should be the native size of the MNIST dataset which is \n",
    "# 28x28 monochrome. Do not resize the data. Your input layer should accept\n",
    "# (28,28) as the input shape only. If you amend this, the tests will fail.\n",
    "#\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def solution_model():\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.reshape(x_train.shape[0] , 28 , 28 , 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0] , 28, 28, 1)\n",
    "\n",
    "    x_train = x_train.astype(\"float32\")\n",
    "    x_train = x_train/255.0\n",
    "    x_test = x_test.astype(\"float32\")\n",
    "    x_test = x_test/255.0\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32 , (3,3) , activation= \"relu\" , input_shape= (28,28,1)),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "        metrics=['acc'])\n",
    "\n",
    "    model.fit(x_train,y_train , epochs = 10 , validation_data = (x_test,y_test) , verbose =1 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "# Note that you'll need to save your model as a .h5 like this.\n",
    "# When you press the Submit and Test button, your saved .h5 model will\n",
    "# be sent to the testing infrastructure for scoring\n",
    "# and the score will be returned to you.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = solution_model()\n",
    "    model.save(\"mymodel.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d7386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-datasets==4.4.0\n",
      "  Downloading tensorflow_datasets-4.4.0-py3-none-any.whl (4.0 MB)\n",
      "     |████████████████████████████████| 4.0 MB 3.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.12.2 in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from tensorflow-datasets==4.4.0) (3.19.4)\n",
      "Collecting future\n",
      "  Using cached future-0.18.2-py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from tensorflow-datasets==4.4.0) (2.27.1)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from tensorflow-datasets==4.4.0) (21.4.0)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "     |████████████████████████████████| 86 kB 855 kB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from tensorflow-datasets==4.4.0) (1.22.2)\n",
      "Collecting promise\n",
      "  Using cached promise-2.3-py3-none-any.whl\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.6.0-py3-none-any.whl (48 kB)\n",
      "     |████████████████████████████████| 48 kB 84 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: absl-py in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from tensorflow-datasets==4.4.0) (1.0.0)\n",
      "Requirement already satisfied: importlib-resources in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from tensorflow-datasets==4.4.0) (5.4.0)\n",
      "Requirement already satisfied: termcolor in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from tensorflow-datasets==4.4.0) (1.1.0)\n",
      "Requirement already satisfied: six in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from tensorflow-datasets==4.4.0) (1.16.0)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0) (2021.10.8)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from importlib-resources->tensorflow-datasets==4.4.0) (3.7.0)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.55.0-py2.py3-none-any.whl (212 kB)\n",
      "     |████████████████████████████████| 212 kB 2.8 MB/s            \n",
      "\u001b[?25hInstalling collected packages: googleapis-common-protos, tqdm, tensorflow-metadata, promise, future, dill, tensorflow-datasets\n",
      "Successfully installed dill-0.3.4 future-0.18.2 googleapis-common-protos-1.55.0 promise-2.3 tensorflow-datasets-4.4.0 tensorflow-metadata-1.6.0 tqdm-4.62.3\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/irfanrah/tf2certify/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting Pillow==8.4.0\n",
      "  Using cached Pillow-8.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Installing collected packages: Pillow\n",
      "Successfully installed Pillow-8.4.0\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/irfanrah/tf2certify/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pandas==1.3.4\n",
      "  Downloading pandas-1.3.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "     |████████████████████████████████| 11.5 MB 68 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from pandas==1.3.4) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from pandas==1.3.4) (1.22.2)\n",
      "Collecting pytz>=2017.3\n",
      "  Using cached pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.3.4) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.3.4 pytz-2021.3\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/irfanrah/tf2certify/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting numpy==1.21.4\n",
      "  Using cached numpy-1.21.4-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.2\n",
      "    Uninstalling numpy-1.22.2:\n",
      "      Successfully uninstalled numpy-1.22.2\n",
      "Successfully installed numpy-1.21.4\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/irfanrah/tf2certify/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting scipy==1.7.3\n",
      "  Using cached scipy-1.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.3 MB)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /home/irfanrah/tf2certify/lib/python3.8/site-packages (from scipy==1.7.3) (1.21.4)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.7.3\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/irfanrah/tf2certify/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow-datasets==4.4.0\n",
    "!pip3 install Pillow==8.4.0\n",
    "!pip3 install pandas==1.3.4\n",
    "!pip3 install numpy==1.21.4\n",
    "!pip3 install scipy==1.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fe13db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
