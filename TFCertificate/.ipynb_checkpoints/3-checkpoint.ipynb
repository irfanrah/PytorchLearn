{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4820878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 206 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12356/1886587940.py:89: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.0824 - acc: 0.5534 - val_loss: 0.7129 - val_acc: 0.5000\n",
      "Epoch 2/9\n",
      "7/7 [==============================] - 7s 995ms/step - loss: 0.7259 - acc: 0.5874 - val_loss: 0.6496 - val_acc: 0.5000\n",
      "Epoch 3/9\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.5762 - acc: 0.6359 - val_loss: 0.5555 - val_acc: 0.5400\n",
      "Epoch 4/9\n",
      "7/7 [==============================] - 7s 993ms/step - loss: 0.3541 - acc: 0.8495 - val_loss: 0.2315 - val_acc: 0.9600\n",
      "Epoch 5/9\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 0.2587 - acc: 0.8981 - val_loss: 0.1960 - val_acc: 0.9600\n",
      "Epoch 6/9\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.1584 - acc: 0.9466 - val_loss: 0.6292 - val_acc: 0.7000\n",
      "Epoch 7/9\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.1208 - acc: 0.9612 - val_loss: 0.1079 - val_acc: 0.9800\n",
      "Epoch 8/9\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0758 - acc: 0.9757 - val_loss: 0.0813 - val_acc: 0.9800\n",
      "Epoch 9/9\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 0.1014 - acc: 0.9563 - val_loss: 0.2651 - val_acc: 0.9400\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
    "# Please note that the weight of the grade for the question is relative\n",
    "# to its difficulty. So your Category 1 question will score significantly\n",
    "# less than your Category 5 question.\n",
    "#\n",
    "# Don't use lambda layers in your model.\n",
    "# You do not need them to solve the question.\n",
    "# Lambda layers are not supported by the grading infrastructure.\n",
    "#\n",
    "# You must use the Submit and Test button to submit your model\n",
    "# at least once in this category before you finally submit your exam,\n",
    "# otherwise you will score zero for this category.\n",
    "# ======================================================================\n",
    "#\n",
    "# Computer vision with CNNs\n",
    "#\n",
    "# Create and train a classifier for horses or humans using the provided data.\n",
    "# Make sure your final layer is a 1 neuron, activated by sigmoid as shown.\n",
    "#\n",
    "# The test will use images that are 300x300 with 3 bytes color depth so be sure to\n",
    "# design your neural network accordingly\n",
    "\n",
    "import tensorflow as tf\n",
    "import urllib\n",
    "import zipfile\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg19 import VGG19,preprocess_input\n",
    "\n",
    "\n",
    "def solution_model():\n",
    "    _TRAIN_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\n",
    "    _TEST_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\n",
    "    urllib.request.urlretrieve(_TRAIN_URL, 'horse-or-human.zip')\n",
    "    local_zip = 'horse-or-human.zip'\n",
    "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "    zip_ref.extractall('tmp/horse-or-human/')\n",
    "    zip_ref.close()\n",
    "    urllib.request.urlretrieve(_TEST_URL, 'testdata.zip')\n",
    "    local_zip = 'testdata.zip'\n",
    "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "    zip_ref.extractall('tmp/testdata/')\n",
    "    zip_ref.close()\n",
    "    \n",
    "    FILE_TRAIN_DIR = 'tmp/testdata/'\n",
    "\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale = 1/255.0 ,validation_split=0.2) \n",
    "        #Your code here. Should at least have a rescale. Other parameters can help with overfitting.)\n",
    "\n",
    "    #validation_datagen = ImageDataGenerator(rescale = 1/255.0)\n",
    "        #Your Code here)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(FILE_TRAIN_DIR, \n",
    "                                                        batch_size = 32, \n",
    "                                                        class_mode = 'categorical' , \n",
    "                                                        target_size = (300,300),\n",
    "                                                        subset='training')\n",
    "        #Your Code Here)\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_directory(FILE_TRAIN_DIR,\n",
    "        target_size=(300, 300),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "        #Your Code Here)\n",
    "        \n",
    "    vgg = VGG19( include_top = False,\n",
    "            input_shape = IMAGE_SIZE,\n",
    "            weights = 'imagenet')\n",
    "    \n",
    "    for layer in vgg.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    x = Flatten()(vgg.output)\n",
    "    prediction = Dense( 2 , activation = 'softmax' )(x)\n",
    "    model = Model( inputs = vgg.input , outputs = prediction )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=['acc'])\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        validation_data=validation_generator)\n",
    "    return model\n",
    "\n",
    "    # NOTE: If training is taking a very long time, you should consider setting the batch size\n",
    "    # appropriately on the generator, and the steps per epoch in the model.fit() function.\n",
    "\n",
    "# Note that you'll need to save your model as a .h5 like this.\n",
    "# When you press the Submit and Test button, your saved .h5 model will\n",
    "# be sent to the testing infrastructure for scoring\n",
    "# and the score will be returned to you.\n",
    "if __name__ == '__main__':\n",
    "    model = solution_model()\n",
    "    model.save(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ccfc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import urllib\n",
    "import zipfile\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "_TRAIN_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\n",
    "_TEST_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\n",
    "urllib.request.urlretrieve(_TRAIN_URL, 'horse-or-human.zip')\n",
    "local_zip = 'horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('tmp/horse-or-human/')\n",
    "zip_ref.close()\n",
    "urllib.request.urlretrieve(_TEST_URL, 'testdata.zip')\n",
    "local_zip = 'testdata.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('tmp/testdata/')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c8501",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls tmp/testdata/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls tmp/testdata/horses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b23f3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
